{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamento de warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r datatran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datatran"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An√°lise da causa do acidente, coluna de texto atrav√©s de Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Manobra de mudan√ßa de faixa',\n",
       "       'Acessar a via sem observar a presen√ßa dos outros ve√≠culos',\n",
       "       'Rea√ß√£o tardia ou ineficiente do condutor',\n",
       "       'Aus√™ncia de rea√ß√£o do condutor', 'Frear bruscamente',\n",
       "       'Demais falhas mec√¢nicas ou el√©tricas', 'Transitar na contram√£o',\n",
       "       'Condutor Dormindo', 'Velocidade Incompat√≠vel',\n",
       "       'Entrada inopinada do pedestre',\n",
       "       'Objeto est√°tico sobre o leito carro√ß√°vel',\n",
       "       'Acumulo de √°gua sobre o pavimento', 'Pedestre andava na pista',\n",
       "       'Ultrapassagem Indevida',\n",
       "       'Trafegar com motocicleta (ou similar) entre as faixas',\n",
       "       'Condutor deixou de manter dist√¢ncia do ve√≠culo da frente',\n",
       "       'Pedestre cruzava a pista fora da faixa',\n",
       "       'Ingest√£o de √°lcool pelo condutor', 'Problema com o freio',\n",
       "       'Acesso irregular', 'Retorno proibido', 'Pista Escorregadia',\n",
       "       'Desrespeitar a prefer√™ncia no cruzamento', 'Pista esburacada',\n",
       "       'Convers√£o proibida', 'Avarias e/ou desgaste excessivo no pneu',\n",
       "       'Ilumina√ß√£o deficiente', 'Curva acentuada', 'Chuva', 'Neblina',\n",
       "       'Transitar no Acostamento',\n",
       "       'Carga excessiva e/ou mal acondicionada',\n",
       "       'Afundamento ou ondula√ß√£o no pavimento', 'Problema na suspens√£o',\n",
       "       'Animais na Pista', 'Desvio tempor√°rio', 'Suic√≠dio (presumido)',\n",
       "       'Acostamento em desn√≠vel', 'Demais falhas na via',\n",
       "       'Ingest√£o de subst√¢ncias psicoativas pelo condutor',\n",
       "       'Condutor usando celular', 'Acumulo de √≥leo sobre o pavimento',\n",
       "       'Mal s√∫bito do condutor', 'Estacionar ou parar em local proibido',\n",
       "       'Aus√™ncia de sinaliza√ß√£o',\n",
       "       'Pedestre - Ingest√£o de √°lcool/ subst√¢ncias psicoativas',\n",
       "       'Declive acentuado', 'Falta de acostamento',\n",
       "       'Demais Fen√¥menos da natureza',\n",
       "       'Transtornos Mentais (exceto suicidio)', 'Fuma√ßa',\n",
       "       'Faixas de tr√¢nsito com largura insuficiente',\n",
       "       'Acumulo de areia ou detritos sobre o pavimento',\n",
       "       'Defici√™ncia do Sistema de Ilumina√ß√£o/Sinaliza√ß√£o',\n",
       "       'Sinaliza√ß√£o mal posicionada', 'Sistema de drenagem ineficiente',\n",
       "       'Condutor desrespeitou a ilumina√ß√£o vermelha do sem√°foro',\n",
       "       'Restri√ß√£o de visibilidade em curvas horizontais',\n",
       "       'Falta de elemento de conten√ß√£o que evite a sa√≠da do leito carro√ß√°vel',\n",
       "       '√Årea urbana sem a presen√ßa de local apropriado para a travessia de pedestres',\n",
       "       'Deixar de acionar o farol da motocicleta (ou similar)',\n",
       "       'Restri√ß√£o de visibilidade em curvas verticais',\n",
       "       'Far√≥is desregulados', 'Modifica√ß√£o proibida',\n",
       "       'Participar de racha', 'Sinaliza√ß√£o encoberta',\n",
       "       'Sem√°foro com defeito'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['causa_acidente'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40481143-703f-4ca3-8f35-edfdfba63f31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Tokeniza√ß√£o para remo√ß√£o de stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Baixar dados necess√°rios do NLTK\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stopwords = set(stopwords.words('portuguese')) | set([\n",
    "    \" \", \"ou\", \"\", \"ok\", \"problema\", \"paciente\", \"necess√°rio\", \"feito\", \"w\", \"devido\",\n",
    "    \"precisa\", \"dr\", \"op√ß√µes\", \"caso\", \"o\", \"x\", \"tentar\", \"ainda\", \"pr√≥ximo\", \"r\",\n",
    "    \"d\", \"desde\", \"teste\", \"testando\", \"resultados\", \"recomendar\", \"pode\", \"por favor\",\n",
    "    \"m√©dico\", \"normal\", \"seria\", \"discutido\", \"medicamento\", \"doen√ßa\",\n",
    "    \"sugerido\", \"considerar\", \"sim\", \"prov√°vel\", \"cl√≠nico\", \"revis√£o\",\n",
    "    \"interno\", \"tratar\", \"rever\", \"semana\", \"ensaio\", \"coment√°rio\", \"rec\",\n",
    "    \"vai\", \"n√≥s\", \"oi\", \"ol√°\", \"cumprimento\", \"gostar\", \"saber\", \"sim\", \"certo\",\n",
    "    \"amanh√£\", \"olhar\", \"dizer\", \"okay\", \"quilograma\", \"zoom\", \"link\", \"tudo bem\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizar e remover stopwords\n",
    "def process_text(text):\n",
    "        tokens = word_tokenize(str(text).lower())  # Tokenizar e converter para min√∫sculas\n",
    "        filtered_tokens = [word for word in tokens if word.isalnum() and word not in custom_stopwords]\n",
    "        return \" \".join(filtered_tokens)  # Reunir palavras filtradas em uma string\n",
    "\n",
    "# Aplicar processamento ao DataFrame\n",
    "df[\"palavras_filtradas\"] = df[\"causa_acidente\"].apply(process_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lematiza√ß√£o e Radicaliza√ß√£o\n",
    "\n",
    "üîπ Lema (Lemmatization): Processo de reduzir palavras √† sua forma base ou raiz, conhecida como lema.\n",
    "\n",
    "üîπ Radical (Stemming): Redu√ß√£o de palavras √† sua forma raiz (stem) sem considerar regras gramaticais ou significado.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def lemma_nltk(df):\n",
    "    # Inicializar o the lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def get_wordnet_pos(word):\n",
    "        \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "        tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "        tag_dict = {\"J\": wordnet.ADJ,\n",
    "                    \"N\": wordnet.NOUN,\n",
    "                    \"V\": wordnet.VERB,\n",
    "                    \"R\": wordnet.ADV}\n",
    "        return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "    def lemmatize_words(text):\n",
    "        words = text.split()\n",
    "        lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in words]\n",
    "        return ' '.join(lemmatized_words)\n",
    "\n",
    "    # Aplicar lemmatization function a coluna do DataFrame\n",
    "    df['lemma'] = df['palavras_filtradas'].apply(lemmatize_words)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_lemma = lemma_nltk(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavras_filtradas</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>manobra mudan√ßa faixa</td>\n",
       "      <td>manobra mudan√ßa faixa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acessar via observar presen√ßa outros ve√≠culos</td>\n",
       "      <td>acessar via observar presen√ßa outros ve√≠culos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rea√ß√£o tardia ineficiente condutor</td>\n",
       "      <td>rea√ß√£o tardia ineficiente condutor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rea√ß√£o tardia ineficiente condutor</td>\n",
       "      <td>rea√ß√£o tardia ineficiente condutor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rea√ß√£o tardia ineficiente condutor</td>\n",
       "      <td>rea√ß√£o tardia ineficiente condutor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aus√™ncia rea√ß√£o condutor</td>\n",
       "      <td>aus√™ncia rea√ß√£o condutor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>manobra mudan√ßa faixa</td>\n",
       "      <td>manobra mudan√ßa faixa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>frear bruscamente</td>\n",
       "      <td>frear bruscamente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rea√ß√£o tardia ineficiente condutor</td>\n",
       "      <td>rea√ß√£o tardia ineficiente condutor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aus√™ncia rea√ß√£o condutor</td>\n",
       "      <td>aus√™ncia rea√ß√£o condutor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              palavras_filtradas  \\\n",
       "0                          manobra mudan√ßa faixa   \n",
       "1  acessar via observar presen√ßa outros ve√≠culos   \n",
       "2             rea√ß√£o tardia ineficiente condutor   \n",
       "3             rea√ß√£o tardia ineficiente condutor   \n",
       "4             rea√ß√£o tardia ineficiente condutor   \n",
       "5                       aus√™ncia rea√ß√£o condutor   \n",
       "6                          manobra mudan√ßa faixa   \n",
       "7                              frear bruscamente   \n",
       "8             rea√ß√£o tardia ineficiente condutor   \n",
       "9                       aus√™ncia rea√ß√£o condutor   \n",
       "\n",
       "                                           lemma  \n",
       "0                          manobra mudan√ßa faixa  \n",
       "1  acessar via observar presen√ßa outros ve√≠culos  \n",
       "2             rea√ß√£o tardia ineficiente condutor  \n",
       "3             rea√ß√£o tardia ineficiente condutor  \n",
       "4             rea√ß√£o tardia ineficiente condutor  \n",
       "5                       aus√™ncia rea√ß√£o condutor  \n",
       "6                          manobra mudan√ßa faixa  \n",
       "7                              frear bruscamente  \n",
       "8             rea√ß√£o tardia ineficiente condutor  \n",
       "9                       aus√™ncia rea√ß√£o condutor  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lemma[['palavras_filtradas', 'lemma']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def stem_nltk_after_lemma(df):\n",
    "    # Inicializar o stemmer\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    def stem_words(text):\n",
    "        # Split do texto em palavras\n",
    "        words = text.split()\n",
    "        # Stem cada palavra\n",
    "        stemmed_words = [stemmer.stem(word) for word in words]\n",
    "        # Join as palavras apos o stemmed words de volta a uma single string\n",
    "        return ' '.join(stemmed_words)\n",
    "\n",
    "    # Aplica a stemming function ao DataFrame\n",
    "    df['normalizado'] = df['lemma'].apply(stem_words)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_final = stem_nltk_after_lemma(df_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavras_filtradas</th>\n",
       "      <th>lemma</th>\n",
       "      <th>normalizado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>manobra mudan√ßa faixa</td>\n",
       "      <td>manobra mudan√ßa faixa</td>\n",
       "      <td>manobra mudan√ßa faixa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acessar via observar presen√ßa outros ve√≠culos</td>\n",
       "      <td>acessar via observar presen√ßa outros ve√≠culos</td>\n",
       "      <td>acessar via observar presen√ßa outro ve√≠culo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rea√ß√£o tardia ineficiente condutor</td>\n",
       "      <td>rea√ß√£o tardia ineficiente condutor</td>\n",
       "      <td>rea√ß√£o tardia ineficient condutor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rea√ß√£o tardia ineficiente condutor</td>\n",
       "      <td>rea√ß√£o tardia ineficiente condutor</td>\n",
       "      <td>rea√ß√£o tardia ineficient condutor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rea√ß√£o tardia ineficiente condutor</td>\n",
       "      <td>rea√ß√£o tardia ineficiente condutor</td>\n",
       "      <td>rea√ß√£o tardia ineficient condutor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aus√™ncia rea√ß√£o condutor</td>\n",
       "      <td>aus√™ncia rea√ß√£o condutor</td>\n",
       "      <td>aus√™ncia rea√ß√£o condutor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>manobra mudan√ßa faixa</td>\n",
       "      <td>manobra mudan√ßa faixa</td>\n",
       "      <td>manobra mudan√ßa faixa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>frear bruscamente</td>\n",
       "      <td>frear bruscamente</td>\n",
       "      <td>frear bruscament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rea√ß√£o tardia ineficiente condutor</td>\n",
       "      <td>rea√ß√£o tardia ineficiente condutor</td>\n",
       "      <td>rea√ß√£o tardia ineficient condutor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aus√™ncia rea√ß√£o condutor</td>\n",
       "      <td>aus√™ncia rea√ß√£o condutor</td>\n",
       "      <td>aus√™ncia rea√ß√£o condutor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              palavras_filtradas  \\\n",
       "0                          manobra mudan√ßa faixa   \n",
       "1  acessar via observar presen√ßa outros ve√≠culos   \n",
       "2             rea√ß√£o tardia ineficiente condutor   \n",
       "3             rea√ß√£o tardia ineficiente condutor   \n",
       "4             rea√ß√£o tardia ineficiente condutor   \n",
       "5                       aus√™ncia rea√ß√£o condutor   \n",
       "6                          manobra mudan√ßa faixa   \n",
       "7                              frear bruscamente   \n",
       "8             rea√ß√£o tardia ineficiente condutor   \n",
       "9                       aus√™ncia rea√ß√£o condutor   \n",
       "\n",
       "                                           lemma  \\\n",
       "0                          manobra mudan√ßa faixa   \n",
       "1  acessar via observar presen√ßa outros ve√≠culos   \n",
       "2             rea√ß√£o tardia ineficiente condutor   \n",
       "3             rea√ß√£o tardia ineficiente condutor   \n",
       "4             rea√ß√£o tardia ineficiente condutor   \n",
       "5                       aus√™ncia rea√ß√£o condutor   \n",
       "6                          manobra mudan√ßa faixa   \n",
       "7                              frear bruscamente   \n",
       "8             rea√ß√£o tardia ineficiente condutor   \n",
       "9                       aus√™ncia rea√ß√£o condutor   \n",
       "\n",
       "                                   normalizado  \n",
       "0                        manobra mudan√ßa faixa  \n",
       "1  acessar via observar presen√ßa outro ve√≠culo  \n",
       "2            rea√ß√£o tardia ineficient condutor  \n",
       "3            rea√ß√£o tardia ineficient condutor  \n",
       "4            rea√ß√£o tardia ineficient condutor  \n",
       "5                     aus√™ncia rea√ß√£o condutor  \n",
       "6                        manobra mudan√ßa faixa  \n",
       "7                             frear bruscament  \n",
       "8            rea√ß√£o tardia ineficient condutor  \n",
       "9                     aus√™ncia rea√ß√£o condutor  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final[['palavras_filtradas', 'lemma', 'normalizado']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ano</th>\n",
       "      <th>feriado</th>\n",
       "      <th>mes</th>\n",
       "      <th>data_inversa</th>\n",
       "      <th>uf</th>\n",
       "      <th>br</th>\n",
       "      <th>km</th>\n",
       "      <th>municipio</th>\n",
       "      <th>causa_acidente</th>\n",
       "      <th>...</th>\n",
       "      <th>mortos</th>\n",
       "      <th>feridos_graves</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>status</th>\n",
       "      <th>regiao</th>\n",
       "      <th>periodo</th>\n",
       "      <th>palavras_filtradas</th>\n",
       "      <th>lemma</th>\n",
       "      <th>normalizado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows √ó 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, ano, feriado, mes, data_inversa, uf, br, km, municipio, causa_acidente, classificacao_acidente, veiculos, condicao_metereologica, fase_dia, dia_semana, tipo_acidente, tipo_pista, mortos, feridos_graves, latitude, longitude, status, regiao, periodo, palavras_filtradas, lemma, normalizado]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 27 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final[df_final['lemma']==''].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA (entendendo o algoritmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import gensim\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lda(df_final, topics, words, threshold):\n",
    "    \"\"\"\n",
    "    Executa a **Latent Dirichlet Allocation (LDA)** em um DataFrame para identificar t√≥picos.\n",
    "\n",
    "    **Par√¢metros:**\n",
    "    df_final (DataFrame): O DataFrame de entrada contendo os dados de texto.\n",
    "    topics (int): O n√∫mero de t√≥picos a identificar.\n",
    "    words (int): O n√∫mero de palavras mais relevantes a serem exibidas para cada t√≥pico.\n",
    "\n",
    "    **Retorna:**\n",
    "    df_topics (DataFrame): O DataFrame de sa√≠da contendo os dados de texto.\n",
    "\n",
    "    Esta fun√ß√£o divide o DataFrame em conjuntos de treino e teste, **vetoriza os dados de texto** usando **TF-IDF**, \n",
    "    ajusta um modelo LDA nos dados de treino e transforma os dados de teste. \n",
    "    Ela imprime o n√∫mero de linhas nos conjuntos de treino e teste, confirma a cria√ß√£o das matrizes correspondentes, \n",
    "    e indica a conclus√£o das fases de treinamento e teste.\n",
    "    \"\"\"\n",
    "\n",
    "    # Separar o DataFrame em conjuntos de treino e teste\n",
    "    train_df = df_final.sample(frac=0.7, random_state=42)\n",
    "    test_df = df_final.drop(train_df.index)\n",
    "\n",
    "    print(f\"Contagem df treino: {len(train_df)}\")\n",
    "    print(f\"Contagem df teste: {len(test_df)}\")\n",
    "\n",
    "    train_texts = train_df['normalizado'].tolist()\n",
    "    test_texts = test_df['normalizado'].tolist()\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    train_matrix = vectorizer.fit_transform(train_texts)\n",
    "    test_matrix = vectorizer.transform(test_texts)\n",
    "\n",
    "    print(f\"Matrix de treino e testes criadas!\")\n",
    "\n",
    "    # Define o n√∫mero de t√≥picos e palavras dentro de cada t√≥pico\n",
    "    num_topics = topics\n",
    "    num_top_words = words\n",
    "\n",
    "    # Cria√ß√£o LDA object\n",
    "    lda = LatentDirichletAllocation(doc_topic_prior=0.5, learning_decay=0.5, learning_method='online', max_iter= 10, topic_word_prior=0.1, n_components=num_topics, random_state=42)\n",
    "\n",
    "    # Fit do modelo na matrix de treino\n",
    "    lda_matrix_train = lda.fit_transform(train_matrix)\n",
    "\n",
    "    print(f\"Treinamento completo!\")\n",
    "\n",
    "    # Transforma a matrix de teste\n",
    "    lda_matrix_test = lda.transform(test_matrix)\n",
    "\n",
    "    print(f\"Teste completo!\")\n",
    "\n",
    "    # Obt√©m os termos de cada t√≥pico\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "    topics = []\n",
    "    top_terms_dict = {}\n",
    "    for idx, topic in enumerate(lda.components_):\n",
    "        top_terms = [terms[i] for i in topic.argsort()[-num_top_words:]]\n",
    "        topics.append((f\"Topic {idx + 1}\", \", \".join(top_terms)))\n",
    "        top_terms_dict[idx] = \", \".join(top_terms)\n",
    "\n",
    "    # Cria√ß√£o df com os t√≥picos\n",
    "    df_topics = pd.DataFrame(topics, columns=[\"Topic\", \"Top Terms\"])\n",
    "\n",
    "    print(f\"T√≥picos gerados!\")\n",
    "\n",
    "    # Teste de perplexidade\n",
    "    perplexity = lda.perplexity(test_matrix)\n",
    "    print(f'Perplexity: {perplexity}')\n",
    " \n",
    "    # Prepara o dado para coherence model\n",
    "    texts = [doc.split() for doc in test_texts]\n",
    "    dictionary = Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "    # Fit do modelo LDA usando gensim\n",
    "    lda_model = gensim.models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=10)\n",
    "\n",
    "    # C√°lculo coherence score\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = coherence_model_lda.get_coherence()\n",
    "    print(f'Coherence Score: {coherence_score}')\n",
    "\n",
    "    # Atribue os t√≥picos para o df original\n",
    "    # O par√¢metro de limite (threshold) √© utilizado para garantir que apenas t√≥picos com uma probabilidade acima do limite especificado sejam atribu√≠dos. Se a maior probabilidade estiver abaixo desse limite, o t√≥pico √© definido como -1, indicando que n√£o h√° uma atribui√ß√£o clara de t√≥pico. Essa abordagem pode ajudar a melhorar a precis√£o do mapeamento de t√≥picos.\n",
    "    num_threshold = threshold\n",
    "    topic_prob_matrix = lda.transform(vectorizer.transform(df_final['normalizado'].tolist()))\n",
    "    df_final['Topic'] = np.where(topic_prob_matrix.max(axis=1) >= num_threshold, topic_prob_matrix.argmax(axis=1), -1)\n",
    "    df_final['Top Terms'] = df_final['Topic'].map(lambda x: top_terms_dict.get(x, ''))\n",
    "\n",
    "    return df_topics, df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contagem df treino: 13996\n",
      "Contagem df teste: 5999\n",
      "Matrix de treino e testes criadas!\n",
      "Treinamento completo!\n",
      "Teste completo!\n",
      "T√≥picos gerados!\n",
      "Perplexity: 47.724964704056994\n",
      "Coherence Score: 0.5833879736271982\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_topics, df_final = lda(df_final, 8, 6, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Top Terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>tr√¢nsito, largura, insuficient, modifica√ß√£o, velocidad, incompat√≠vel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>trafegar, similar, motocicleta, mudan√ßa, manobra, faixa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>chuva, mal, condutor, rea√ß√£o, ineficient, tardia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>outro, observar, acessar, presen√ßa, via, ve√≠culo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>andava, cruzamento, prefer√™ncia, desrespeitar, pedestr, pista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>mec√¢nica, falha, demai, condutor, rea√ß√£o, aus√™ncia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>sobr, acostamento, ultrapassagem, indevida, contram√£o, transitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>animai, freio, √°lcool, ingest√£o, dormindo, condutor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  \\\n",
       "16      0   \n",
       "0       1   \n",
       "2       2   \n",
       "1       3   \n",
       "17      4   \n",
       "5       5   \n",
       "12      6   \n",
       "14      7   \n",
       "\n",
       "                                                               Top Terms  \n",
       "16  tr√¢nsito, largura, insuficient, modifica√ß√£o, velocidad, incompat√≠vel  \n",
       "0                trafegar, similar, motocicleta, mudan√ßa, manobra, faixa  \n",
       "2                       chuva, mal, condutor, rea√ß√£o, ineficient, tardia  \n",
       "1                       outro, observar, acessar, presen√ßa, via, ve√≠culo  \n",
       "17         andava, cruzamento, prefer√™ncia, desrespeitar, pedestr, pista  \n",
       "5                     mec√¢nica, falha, demai, condutor, rea√ß√£o, aus√™ncia  \n",
       "12      sobr, acostamento, ultrapassagem, indevida, contram√£o, transitar  \n",
       "14                   animai, freio, √°lcool, ingest√£o, dormindo, condutor  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final[['Topic', 'Top Terms']].drop_duplicates().sort_values(by='Topic', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "topico_para_categoria = {\n",
    "    0: \"Infra√ß√£o de Tr√¢nsito\",\n",
    "    1: \"Obst√°culo ou Motocicleta envolvida\",\n",
    "    2: \"Condutor rea√ß√£o tardia\",\n",
    "    3: \"Manobra imprudente condutor\",\n",
    "    4: \"Manobra imprudente condutor\",\n",
    "    5: \"Problema mec√¢nico no ve√≠culo\",\n",
    "    6: \"Acostamento ou Ultrapassagem\",\n",
    "    7: \"Condutor sob efeito de subst√¢ncias\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explorando os t√≥picos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>causa_acidente</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Top Terms</th>\n",
       "      <th>normalizado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acessar a via sem observar a presen√ßa dos outros ve√≠culos</td>\n",
       "      <td>3</td>\n",
       "      <td>outro, observar, acessar, presen√ßa, via, ve√≠culo</td>\n",
       "      <td>acessar via observar presen√ßa outro ve√≠culo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              causa_acidente  Topic  \\\n",
       "1  Acessar a via sem observar a presen√ßa dos outros ve√≠culos      3   \n",
       "\n",
       "                                          Top Terms  \\\n",
       "1  outro, observar, acessar, presen√ßa, via, ve√≠culo   \n",
       "\n",
       "                                   normalizado  \n",
       "1  acessar via observar presen√ßa outro ve√≠culo  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final[df_final['normalizado'].str.contains('observar', na=False)][['causa_acidente','Topic', 'Top Terms', 'normalizado']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Top Terms</th>\n",
       "      <th>normalizado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>chuva, mal, condutor, rea√ß√£o, ineficient, tardia</td>\n",
       "      <td>rea√ß√£o tardia ineficient condutor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>4</td>\n",
       "      <td>andava, cruzamento, prefer√™ncia, desrespeitar, pedestr, pista</td>\n",
       "      <td>sistema drenagem ineficient</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic                                                      Top Terms  \\\n",
       "2         2               chuva, mal, condutor, rea√ß√£o, ineficient, tardia   \n",
       "1710      4  andava, cruzamento, prefer√™ncia, desrespeitar, pedestr, pista   \n",
       "\n",
       "                            normalizado  \n",
       "2     rea√ß√£o tardia ineficient condutor  \n",
       "1710        sistema drenagem ineficient  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final[df_final['normalizado'].str.contains('ineficient', na=False)][['Topic', 'Top Terms', 'normalizado']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisando Medidas de Acur√°cia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Perplexity\n",
    "A perplexidade √© uma medida de qu√£o bem um modelo probabil√≠stico prev√™ um conjunto de amostras. No contexto de LDA (Latent Dirichlet Allocation), valores mais baixos de perplexidade indicam um melhor ajuste aos dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Coherence Score\n",
    "A coer√™ncia mede a similaridade sem√¢ntica entre as palavras mais relevantes dentro dos t√≥picos. Pontua√ß√µes mais altas indicam t√≥picos de melhor qualidade. \n",
    "\n",
    "Um Coherence Score de 0.5329 indica que os t√≥picos gerados pelo modelo LDA possuem um n√≠vel razo√°vel de interpretabilidade e similaridade sem√¢ntica.\n",
    "Interpreta√ß√£o da pontua√ß√£o:\n",
    "\n",
    "- Acima de 0.5 ‚Üí Indica que os t√≥picos t√™m uma coer√™ncia moderada a boa, com palavras que fazem sentido juntas.\n",
    "- Entre 0.6 e 0.8 ‚Üí Indica boa coer√™ncia sem√¢ntica, sugerindo que os t√≥picos est√£o bem agrupados e interpret√°veis.\n",
    "- Acima de 0.8 ‚Üí Indica alta qualidade, onde os t√≥picos gerados s√£o claramente diferenci√°veis e t√™m forte significado sem√¢ntico.\n",
    "\n",
    "üîπ Resultado (0.5329) sugere que os t√≥picos fazem sentido, mas ainda h√° espa√ßo para refinamento. Algumas melhorias que podem ser feitas para aumentar a coer√™ncia:\n",
    "\n",
    "- Refinar o pr√©-processamento do texto ‚Üí Remover palavras irrelevantes ou normalizar melhor o texto.\n",
    "- Ajustar o n√∫mero de t√≥picos ‚Üí Talvez reduzir ou aumentar um pouco os t√≥picos ajude na segmenta√ß√£o das palavras.\n",
    "- Alterar hiperpar√¢metros do LDA ‚Üí Testar ajustes na alpha e beta, al√©m de aumentar o n√∫mero de itera√ß√µes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRID SEARCH \n",
    "\n",
    ">- simplificado devido √† problemas de performance do micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.grid_search import grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contagem df treino: 13996\n",
      "Contagem df teste: 5999\n",
      "Matrix de treino e testes criadas!\n",
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.3, learning_method=batch, max_iter=5, n_components=5, topic_word_prior=0.01; total time=   2.7s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.3, learning_method=batch, max_iter=5, n_components=5, topic_word_prior=0.01; total time=   2.7s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.3, learning_method=batch, max_iter=5, n_components=5, topic_word_prior=0.1; total time=   2.8s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.3, learning_method=batch, max_iter=5, n_components=5, topic_word_prior=0.1; total time=   2.7s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.3, learning_method=batch, max_iter=5, n_components=8, topic_word_prior=0.01; total time=   2.8s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.3, learning_method=batch, max_iter=5, n_components=8, topic_word_prior=0.01; total time=   3.3s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.3, learning_method=batch, max_iter=5, n_components=8, topic_word_prior=0.1; total time=   2.8s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.3, learning_method=batch, max_iter=5, n_components=8, topic_word_prior=0.1; total time=   2.9s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.3, learning_method=batch, max_iter=10, n_components=5, topic_word_prior=0.01; total time=   5.2s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.3, learning_method=batch, max_iter=10, n_components=5, topic_word_prior=0.01; total time=   4.6s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.3, learning_method=batch, max_iter=10, n_components=5, topic_word_prior=0.1; total time=   4.3s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.3, learning_method=batch, max_iter=10, n_components=5, topic_word_prior=0.1; total time=   4.5s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.3, learning_method=batch, max_iter=10, n_components=8, topic_word_prior=0.01; total time=   4.7s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.3, learning_method=batch, max_iter=10, n_components=8, topic_word_prior=0.01; total time=   4.5s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.3, learning_method=batch, max_iter=10, n_components=8, topic_word_prior=0.1; total time=   4.5s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.3, learning_method=batch, max_iter=10, n_components=8, topic_word_prior=0.1; total time=   4.3s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.5, learning_method=batch, max_iter=5, n_components=5, topic_word_prior=0.01; total time=   2.7s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.5, learning_method=batch, max_iter=5, n_components=5, topic_word_prior=0.01; total time=   2.7s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.5, learning_method=batch, max_iter=5, n_components=5, topic_word_prior=0.1; total time=   3.1s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.5, learning_method=batch, max_iter=5, n_components=5, topic_word_prior=0.1; total time=   3.2s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.5, learning_method=batch, max_iter=5, n_components=8, topic_word_prior=0.01; total time=   3.1s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.5, learning_method=batch, max_iter=5, n_components=8, topic_word_prior=0.01; total time=   3.4s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.5, learning_method=batch, max_iter=5, n_components=8, topic_word_prior=0.1; total time=   3.0s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.5, learning_method=batch, max_iter=5, n_components=8, topic_word_prior=0.1; total time=   3.3s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.5, learning_method=batch, max_iter=10, n_components=5, topic_word_prior=0.01; total time=   4.8s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.5, learning_method=batch, max_iter=10, n_components=5, topic_word_prior=0.01; total time=   4.5s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.5, learning_method=batch, max_iter=10, n_components=5, topic_word_prior=0.1; total time=   5.2s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.5, learning_method=batch, max_iter=10, n_components=5, topic_word_prior=0.1; total time=   4.9s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.5, learning_method=batch, max_iter=10, n_components=8, topic_word_prior=0.01; total time=   6.1s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.5, learning_method=batch, max_iter=10, n_components=8, topic_word_prior=0.01; total time=   4.5s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.5, learning_method=batch, max_iter=10, n_components=8, topic_word_prior=0.1; total time=   5.0s\n",
      "[CV] END doc_topic_prior=0.1, learning_decay=0.5, learning_method=batch, max_iter=10, n_components=8, topic_word_prior=0.1; total time=   4.8s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.3, learning_method=batch, max_iter=5, n_components=5, topic_word_prior=0.01; total time=   4.3s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.3, learning_method=batch, max_iter=5, n_components=5, topic_word_prior=0.01; total time=   4.6s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.3, learning_method=batch, max_iter=5, n_components=5, topic_word_prior=0.1; total time=   4.4s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.3, learning_method=batch, max_iter=5, n_components=5, topic_word_prior=0.1; total time=   4.7s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.3, learning_method=batch, max_iter=5, n_components=8, topic_word_prior=0.01; total time=   4.1s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.3, learning_method=batch, max_iter=5, n_components=8, topic_word_prior=0.01; total time=   4.3s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.3, learning_method=batch, max_iter=5, n_components=8, topic_word_prior=0.1; total time=   4.1s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.3, learning_method=batch, max_iter=5, n_components=8, topic_word_prior=0.1; total time=   4.1s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.3, learning_method=batch, max_iter=10, n_components=5, topic_word_prior=0.01; total time=   6.3s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.3, learning_method=batch, max_iter=10, n_components=5, topic_word_prior=0.01; total time=   5.9s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.3, learning_method=batch, max_iter=10, n_components=5, topic_word_prior=0.1; total time=   6.0s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.3, learning_method=batch, max_iter=10, n_components=5, topic_word_prior=0.1; total time=   5.8s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.3, learning_method=batch, max_iter=10, n_components=8, topic_word_prior=0.01; total time=   5.8s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.3, learning_method=batch, max_iter=10, n_components=8, topic_word_prior=0.01; total time=   6.0s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.3, learning_method=batch, max_iter=10, n_components=8, topic_word_prior=0.1; total time=   6.1s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.3, learning_method=batch, max_iter=10, n_components=8, topic_word_prior=0.1; total time=   5.9s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.5, learning_method=batch, max_iter=5, n_components=5, topic_word_prior=0.01; total time=   4.6s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.5, learning_method=batch, max_iter=5, n_components=5, topic_word_prior=0.01; total time=   4.3s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.5, learning_method=batch, max_iter=5, n_components=5, topic_word_prior=0.1; total time=   4.1s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.5, learning_method=batch, max_iter=5, n_components=5, topic_word_prior=0.1; total time=   4.8s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.5, learning_method=batch, max_iter=5, n_components=8, topic_word_prior=0.01; total time=   4.4s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.5, learning_method=batch, max_iter=5, n_components=8, topic_word_prior=0.01; total time=   4.4s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.5, learning_method=batch, max_iter=5, n_components=8, topic_word_prior=0.1; total time=   4.1s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.5, learning_method=batch, max_iter=5, n_components=8, topic_word_prior=0.1; total time=   4.2s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.5, learning_method=batch, max_iter=10, n_components=5, topic_word_prior=0.01; total time=   6.0s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.5, learning_method=batch, max_iter=10, n_components=5, topic_word_prior=0.01; total time=   6.1s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.5, learning_method=batch, max_iter=10, n_components=5, topic_word_prior=0.1; total time=   5.9s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.5, learning_method=batch, max_iter=10, n_components=5, topic_word_prior=0.1; total time=   6.3s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.5, learning_method=batch, max_iter=10, n_components=8, topic_word_prior=0.01; total time=   5.5s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.5, learning_method=batch, max_iter=10, n_components=8, topic_word_prior=0.01; total time=   5.4s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.5, learning_method=batch, max_iter=10, n_components=8, topic_word_prior=0.1; total time=   5.6s\n",
      "[CV] END doc_topic_prior=0.5, learning_decay=0.5, learning_method=batch, max_iter=10, n_components=8, topic_word_prior=0.1; total time=   5.6s\n",
      "Best Parameters: {'doc_topic_prior': 0.1, 'learning_decay': 0.3, 'learning_method': 'batch', 'max_iter': 10, 'n_components': 5, 'topic_word_prior': 0.1}\n",
      "Teste completo!\n",
      "T√≥picos gerados!\n",
      "Perplexity: 37.11761939364298\n",
      "Coherence Score: 0.5933707924030474\n",
      "Wall time: 5min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_topics, df_final = grid_search(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Top Terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>largura, curva, acentuada, incompat√≠vel, velocidad, tardia, ineficient, aus√™ncia, condutor, rea√ß√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>cruzamento, prefer√™ncia, desrespeitar, trafegar, similar, motocicleta, freio, mudan√ßa, manobra, faixa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>carga, s√∫bito, chuva, mal, √°lcool, ingest√£o, indevida, ultrapassagem, condutor, dormindo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>presen√ßa, acessar, outro, observar, mec√¢nica, el√©trica, via, demai, falha, ve√≠culo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>pneu, desgast, avaria, excessivo, animai, andava, acostamento, pista, contram√£o, transitar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  \\\n",
       "2       0   \n",
       "0       1   \n",
       "14      2   \n",
       "1       3   \n",
       "12      4   \n",
       "\n",
       "                                                                                                Top Terms  \n",
       "2      largura, curva, acentuada, incompat√≠vel, velocidad, tardia, ineficient, aus√™ncia, condutor, rea√ß√£o  \n",
       "0   cruzamento, prefer√™ncia, desrespeitar, trafegar, similar, motocicleta, freio, mudan√ßa, manobra, faixa  \n",
       "14               carga, s√∫bito, chuva, mal, √°lcool, ingest√£o, indevida, ultrapassagem, condutor, dormindo  \n",
       "1                      presen√ßa, acessar, outro, observar, mec√¢nica, el√©trica, via, demai, falha, ve√≠culo  \n",
       "12             pneu, desgast, avaria, excessivo, animai, andava, acostamento, pista, contram√£o, transitar  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final[['Topic', 'Top Terms']].drop_duplicates().sort_values(by='Topic', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "topico_para_categoria = {\n",
    "    0: \"Condutor rea√ß√£o tardia\",\n",
    "    1: \"Infra√ß√£o de Tr√¢nsito\",\n",
    "    2: \"Condutor sob efeitos de subst√¢ncias\",\n",
    "    3: \"Problema mec√¢nico no ve√≠culo\",\n",
    "    4: \"Manobra imprudente condutor\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['Categoria'] = df_final['Topic'].map(topico_para_categoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categoria</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Top Terms</th>\n",
       "      <th>normalizado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Infra√ß√£o de Tr√¢nsito</td>\n",
       "      <td>1</td>\n",
       "      <td>cruzamento, prefer√™ncia, desrespeitar, trafegar, similar, motocicleta, freio, mudan√ßa, manobra, faixa</td>\n",
       "      <td>manobra mudan√ßa faixa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Problema mec√¢nico no ve√≠culo</td>\n",
       "      <td>3</td>\n",
       "      <td>presen√ßa, acessar, outro, observar, mec√¢nica, el√©trica, via, demai, falha, ve√≠culo</td>\n",
       "      <td>acessar via observar presen√ßa outro ve√≠culo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Condutor rea√ß√£o tardia</td>\n",
       "      <td>0</td>\n",
       "      <td>largura, curva, acentuada, incompat√≠vel, velocidad, tardia, ineficient, aus√™ncia, condutor, rea√ß√£o</td>\n",
       "      <td>rea√ß√£o tardia ineficient condutor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Condutor rea√ß√£o tardia</td>\n",
       "      <td>0</td>\n",
       "      <td>largura, curva, acentuada, incompat√≠vel, velocidad, tardia, ineficient, aus√™ncia, condutor, rea√ß√£o</td>\n",
       "      <td>rea√ß√£o tardia ineficient condutor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Condutor rea√ß√£o tardia</td>\n",
       "      <td>0</td>\n",
       "      <td>largura, curva, acentuada, incompat√≠vel, velocidad, tardia, ineficient, aus√™ncia, condutor, rea√ß√£o</td>\n",
       "      <td>rea√ß√£o tardia ineficient condutor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19993</th>\n",
       "      <td>Problema mec√¢nico no ve√≠culo</td>\n",
       "      <td>3</td>\n",
       "      <td>presen√ßa, acessar, outro, observar, mec√¢nica, el√©trica, via, demai, falha, ve√≠culo</td>\n",
       "      <td>acessar via observar presen√ßa outro ve√≠culo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>Condutor sob efeitos de subst√¢ncias</td>\n",
       "      <td>2</td>\n",
       "      <td>carga, s√∫bito, chuva, mal, √°lcool, ingest√£o, indevida, ultrapassagem, condutor, dormindo</td>\n",
       "      <td>ingest√£o √°lcool condutor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>Infra√ß√£o de Tr√¢nsito</td>\n",
       "      <td>1</td>\n",
       "      <td>cruzamento, prefer√™ncia, desrespeitar, trafegar, similar, motocicleta, freio, mudan√ßa, manobra, faixa</td>\n",
       "      <td>freio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>Problema mec√¢nico no ve√≠culo</td>\n",
       "      <td>3</td>\n",
       "      <td>presen√ßa, acessar, outro, observar, mec√¢nica, el√©trica, via, demai, falha, ve√≠culo</td>\n",
       "      <td>condutor deixou manter dist√¢ncia ve√≠culo frent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>Condutor rea√ß√£o tardia</td>\n",
       "      <td>0</td>\n",
       "      <td>largura, curva, acentuada, incompat√≠vel, velocidad, tardia, ineficient, aus√™ncia, condutor, rea√ß√£o</td>\n",
       "      <td>velocidad incompat√≠vel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19995 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Categoria  Topic  \\\n",
       "0                     Infra√ß√£o de Tr√¢nsito      1   \n",
       "1             Problema mec√¢nico no ve√≠culo      3   \n",
       "2                   Condutor rea√ß√£o tardia      0   \n",
       "3                   Condutor rea√ß√£o tardia      0   \n",
       "4                   Condutor rea√ß√£o tardia      0   \n",
       "...                                    ...    ...   \n",
       "19993         Problema mec√¢nico no ve√≠culo      3   \n",
       "19994  Condutor sob efeitos de subst√¢ncias      2   \n",
       "19995                 Infra√ß√£o de Tr√¢nsito      1   \n",
       "19996         Problema mec√¢nico no ve√≠culo      3   \n",
       "19997               Condutor rea√ß√£o tardia      0   \n",
       "\n",
       "                                                                                                   Top Terms  \\\n",
       "0      cruzamento, prefer√™ncia, desrespeitar, trafegar, similar, motocicleta, freio, mudan√ßa, manobra, faixa   \n",
       "1                         presen√ßa, acessar, outro, observar, mec√¢nica, el√©trica, via, demai, falha, ve√≠culo   \n",
       "2         largura, curva, acentuada, incompat√≠vel, velocidad, tardia, ineficient, aus√™ncia, condutor, rea√ß√£o   \n",
       "3         largura, curva, acentuada, incompat√≠vel, velocidad, tardia, ineficient, aus√™ncia, condutor, rea√ß√£o   \n",
       "4         largura, curva, acentuada, incompat√≠vel, velocidad, tardia, ineficient, aus√™ncia, condutor, rea√ß√£o   \n",
       "...                                                                                                      ...   \n",
       "19993                     presen√ßa, acessar, outro, observar, mec√¢nica, el√©trica, via, demai, falha, ve√≠culo   \n",
       "19994               carga, s√∫bito, chuva, mal, √°lcool, ingest√£o, indevida, ultrapassagem, condutor, dormindo   \n",
       "19995  cruzamento, prefer√™ncia, desrespeitar, trafegar, similar, motocicleta, freio, mudan√ßa, manobra, faixa   \n",
       "19996                     presen√ßa, acessar, outro, observar, mec√¢nica, el√©trica, via, demai, falha, ve√≠culo   \n",
       "19997     largura, curva, acentuada, incompat√≠vel, velocidad, tardia, ineficient, aus√™ncia, condutor, rea√ß√£o   \n",
       "\n",
       "                                          normalizado  \n",
       "0                               manobra mudan√ßa faixa  \n",
       "1         acessar via observar presen√ßa outro ve√≠culo  \n",
       "2                   rea√ß√£o tardia ineficient condutor  \n",
       "3                   rea√ß√£o tardia ineficient condutor  \n",
       "4                   rea√ß√£o tardia ineficient condutor  \n",
       "...                                               ...  \n",
       "19993     acessar via observar presen√ßa outro ve√≠culo  \n",
       "19994                        ingest√£o √°lcool condutor  \n",
       "19995                                           freio  \n",
       "19996  condutor deixou manter dist√¢ncia ve√≠culo frent  \n",
       "19997                          velocidad incompat√≠vel  \n",
       "\n",
       "[19995 rows x 4 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final[['Categoria', 'Topic', 'Top Terms', 'normalizado']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando para o PowerBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('./resultados/Data categorizado.csv', index=False, sep=';')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "consult_nlp_vivi",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
